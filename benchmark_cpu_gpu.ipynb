{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLSQP-JAX: CPU vs GPU Benchmark\n",
    "\n",
    "This notebook benchmarks the [slsqp-jax](https://github.com/lucianopaz/slsqp-jax) constrained optimizer across problem sizes to compare **JAX CPU**, **JAX GPU**, and **SciPy** execution times.\n",
    "\n",
    "We solve constrained quadratic problems at dimensions **n = 5, 20, 100, 500, 1000** and\n",
    "report wall-clock times for all backends. Finally, we tackle a **100,000-dimensional constrained portfolio allocation** on both CPU and GPU to demonstrate large-scale capability.\n",
    "\n",
    "> **Requirements** â€” Run this notebook on Google Colab with a **GPU runtime**.\\\n",
    "> Go to **Runtime â†’ Change runtime type â†’ T4 GPU** (or better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade JAX + CUDA plugin to a compatible set, then install slsqp-jax.\n",
    "# Colab ships an older jax-cuda12-plugin that is incompatible with jax>=0.9.\n",
    "!uv pip install jax[cuda12] git+https://github.com/lucianopaz/slsqp-jax.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optimistix as optx\n",
    "\n",
    "from slsqp_jax import SLSQP\n",
    "\n",
    "# Enable 64-bit precision for numerical accuracy\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# --- Hardware verification ---\n",
    "print(f\"JAX version : {jax.__version__}\")\n",
    "print(f\"All devices : {jax.devices()}\")\n",
    "\n",
    "try:\n",
    "    gpu_devices = jax.devices(\"gpu\")\n",
    "    print(f\"\\u2705 GPU detected: {gpu_devices}\")\n",
    "    gpu_available = True\n",
    "except RuntimeError:\n",
    "    print(\"\\u274c No GPU found. Enable GPU in Runtime > Change runtime type.\")\n",
    "    gpu_available = False\n",
    "\n",
    "cpu_device = jax.devices(\"cpu\")[0]\n",
    "gpu_device = jax.devices(\"gpu\")[0] if gpu_available else cpu_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU vs GPU Benchmark\n",
    "\n",
    "For each problem dimension **n**, we create a constrained weighted quadratic:\n",
    "\n",
    "$$\n",
    "\\min_x \\sum_{i=1}^n w_i\\,(x_i - t_i)^2\n",
    "\\quad\\text{s.t.}\\quad\n",
    "\\sum_i x_i = n,\\;\\; x_j \\ge 0 \\;\\text{for}\\; j=0,\\dots,3\n",
    "$$\n",
    "\n",
    "where $w_i$ are linearly spaced in $[1,\\,10]$, and the target $t_i = -2$ for the first 4 variables and $t_i = 1$ for the rest. The 4 box constraints are **active** at the solution (the solver wants $x_{0..3} = -2$ but is prevented), while only 5 total constraints keep the QP subproblem's $AA^T$ system at a\n",
    "numerically stable $5 \\times 5$.\n",
    "\n",
    "Each benchmark:\n",
    "1. JIT-compiles the full `optimistix.minimise` call (all SLSQP iterations compiled into a single XLA program).\n",
    "2. Runs a **warmup** pass to trigger compilation.\n",
    "3. Times multiple post-compilation runs and reports the average.\n",
    "\n",
    "> **Note on GPU vs CPU for iterative solvers** â€” SLSQP uses `jax.lax.while_loop` for the outer iteration and the active-set QP subproblem. Each loop iteration incurs GPU kernel-launch and host-device synchronisation overhead. For small to moderate **n** the per-step linear algebra (O(kn) L-BFGS HVPs, O(mn) projections)\n",
    "> is too cheap to offset that overhead, so **CPU is expected to be faster** at these sizes. The GPU advantage appears for large **n** (thousands of variables) where the vectorised operations dominate â€” as demonstrated in the 100k portfolio problem at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize as scipy_minimize\n",
    "\n",
    "N_INEQ = 4  # fixed number of box constraints (independent of n)\n",
    "\n",
    "\n",
    "def make_benchmark_problem(n):\n",
    "    \"\"\"Create a constrained quadratic with 1 equality + 4 inequality constraints.\n",
    "\n",
    "    The first 4 variables target -2 (but are constrained >= 0), so the\n",
    "    inequality constraints are active at the solution.  The remaining\n",
    "    n-4 variables target 1 and are unconstrained from below.\n",
    "\n",
    "    Returns (solver, objective, x0, scipy_problem_dict).\n",
    "    \"\"\"\n",
    "    weights = jnp.linspace(1.0, 10.0, n)\n",
    "    target = jnp.ones(n).at[: min(N_INEQ, n)].set(-2.0)\n",
    "\n",
    "    # Convert to numpy for scipy compatibility\n",
    "    weights_np = np.asarray(weights)\n",
    "    target_np = np.asarray(target)\n",
    "\n",
    "    def objective(x, args):\n",
    "        return jnp.sum(weights * (x - target) ** 2), None\n",
    "\n",
    "    def eq_constraint(x, args):\n",
    "        return jnp.array([jnp.sum(x) - float(n)])\n",
    "\n",
    "    n_ineq = min(N_INEQ, n)\n",
    "\n",
    "    def ineq_constraint(x, args):\n",
    "        return x[:n_ineq]  # x[0], ..., x[n_ineq-1] >= 0\n",
    "\n",
    "    solver = SLSQP(\n",
    "        rtol=1e-6,\n",
    "        atol=1e-6,\n",
    "        max_steps=200,\n",
    "        eq_constraint_fn=eq_constraint,\n",
    "        n_eq_constraints=1,\n",
    "        ineq_constraint_fn=ineq_constraint,\n",
    "        n_ineq_constraints=n_ineq,\n",
    "        lbfgs_memory=10,\n",
    "    )\n",
    "\n",
    "    # SciPy problem definition (for comparison)\n",
    "    def scipy_objective(x):\n",
    "        return np.sum(weights_np * (x - target_np) ** 2)\n",
    "\n",
    "    def scipy_eq_constraint(x):\n",
    "        return np.sum(x) - float(n)\n",
    "\n",
    "    scipy_constraints = [\n",
    "        {\"type\": \"eq\", \"fun\": scipy_eq_constraint},\n",
    "    ]\n",
    "    # Add inequality constraints: x[i] >= 0 for i in range(n_ineq)\n",
    "    for i in range(n_ineq):\n",
    "        scipy_constraints.append({\"type\": \"ineq\", \"fun\": lambda x, i=i: x[i]})\n",
    "\n",
    "    scipy_problem = {\n",
    "        \"fun\": scipy_objective,\n",
    "        \"constraints\": scipy_constraints,\n",
    "    }\n",
    "\n",
    "    x0 = jnp.ones(n)  # feasible: sum = n, x[:4] = 1 >= 0\n",
    "    return solver, objective, x0, scipy_problem\n",
    "\n",
    "\n",
    "def solve_with_scipy(scipy_problem, x0_np):\n",
    "    \"\"\"Solve the problem using scipy.optimize.minimize with SLSQP.\n",
    "\n",
    "    Returns (solution, time_seconds, success).\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    result = scipy_minimize(\n",
    "        scipy_problem[\"fun\"],\n",
    "        x0_np,\n",
    "        method=\"SLSQP\",\n",
    "        constraints=scipy_problem[\"constraints\"],\n",
    "        options={\"ftol\": 1e-9, \"maxiter\": 200},\n",
    "    )\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    return result.x, elapsed, result.success\n",
    "\n",
    "\n",
    "def check_solutions_match(sol_jax, sol_scipy, rtol=1e-4, atol=1e-5):\n",
    "    \"\"\"Check if JAX and SciPy solutions match within tolerance.\n",
    "\n",
    "    Returns (match, max_diff).\n",
    "    \"\"\"\n",
    "    sol_jax_np = np.asarray(sol_jax)\n",
    "    sol_scipy_np = np.asarray(sol_scipy)\n",
    "\n",
    "    # Handle NaN in JAX solution\n",
    "    if np.any(np.isnan(sol_jax_np)):\n",
    "        return False, np.inf\n",
    "\n",
    "    diff = np.abs(sol_jax_np - sol_scipy_np)\n",
    "    max_diff = float(np.max(diff))\n",
    "    match = np.allclose(sol_jax_np, sol_scipy_np, rtol=rtol, atol=atol)\n",
    "\n",
    "    return match, max_diff\n",
    "\n",
    "\n",
    "def benchmark_on_device(solve_fn, x0, device, n_loops=10):\n",
    "    \"\"\"Benchmark a JIT-compiled solve function on *device*.\n",
    "\n",
    "    Returns (avg_seconds, std_seconds, solution_array).\n",
    "    \"\"\"\n",
    "    x0_dev = jax.device_put(x0, device)\n",
    "\n",
    "    # Warmup â€” triggers JIT compilation for this device\n",
    "    result = solve_fn(x0_dev)\n",
    "    result.block_until_ready()\n",
    "\n",
    "    # Timed runs\n",
    "    times = []\n",
    "    for _ in range(n_loops):\n",
    "        t0 = time.perf_counter()\n",
    "        result = solve_fn(x0_dev)\n",
    "        result.block_until_ready()  # critical for async GPU dispatch\n",
    "        times.append(time.perf_counter() - t0)\n",
    "\n",
    "    return float(np.mean(times)), float(np.std(times)), np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Run benchmarks --------------------------------------------------------\n",
    "problem_sizes = [5, 20, 100, 500, 1000]\n",
    "n_loops = 10\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for n in problem_sizes:\n",
    "    print(f\"\\n{'=' * 65}\")\n",
    "    print(f\" Problem dimension  n = {n}\")\n",
    "    print(f\"{'=' * 65}\")\n",
    "\n",
    "    solver, objective, x0, scipy_problem = make_benchmark_problem(n)\n",
    "\n",
    "    # Build a single JIT-compiled function for this problem.\n",
    "    # Passing solver/objective via default-arg capture so each\n",
    "    # iteration of the loop gets its own compiled function.\n",
    "    @jax.jit\n",
    "    def solve(x0, _s=solver, _o=objective):\n",
    "        sol = optx.minimise(\n",
    "            _o,\n",
    "            _s,\n",
    "            x0,\n",
    "            has_aux=True,\n",
    "            max_steps=200,\n",
    "            throw=False,\n",
    "        )\n",
    "        return sol.value\n",
    "\n",
    "    entry = {}\n",
    "\n",
    "    # --- SciPy reference ---\n",
    "    print(\"  Running SciPy SLSQP ...\", end=\" \", flush=True)\n",
    "    x0_np = np.asarray(x0)\n",
    "    scipy_sol, scipy_time, scipy_success = solve_with_scipy(scipy_problem, x0_np)\n",
    "    print(f\"done  â†’  {scipy_time * 1000:8.2f} ms (success={scipy_success})\")\n",
    "    entry[\"scipy\"] = {\"time\": scipy_time, \"sol\": scipy_sol, \"success\": scipy_success}\n",
    "\n",
    "    # --- CPU ---\n",
    "    print(\"  Compiling for CPU ...\", end=\" \", flush=True)\n",
    "    cpu_avg, cpu_std, cpu_sol = benchmark_on_device(\n",
    "        solve,\n",
    "        x0,\n",
    "        cpu_device,\n",
    "        n_loops,\n",
    "    )\n",
    "    print(f\"done  â†’  {cpu_avg * 1000:8.2f} Â± {cpu_std * 1000:.2f} ms\")\n",
    "    entry[\"cpu\"] = {\"avg\": cpu_avg, \"std\": cpu_std, \"sol\": cpu_sol}\n",
    "\n",
    "    # Check CPU vs SciPy match\n",
    "    cpu_match, cpu_max_diff = check_solutions_match(cpu_sol, scipy_sol)\n",
    "    entry[\"cpu\"][\"match_scipy\"] = cpu_match\n",
    "    entry[\"cpu\"][\"max_diff\"] = cpu_max_diff\n",
    "\n",
    "    # --- GPU ---\n",
    "    if gpu_available:\n",
    "        print(\"  Compiling for GPU ...\", end=\" \", flush=True)\n",
    "        gpu_avg, gpu_std, gpu_sol = benchmark_on_device(\n",
    "            solve,\n",
    "            x0,\n",
    "            gpu_device,\n",
    "            n_loops,\n",
    "        )\n",
    "        print(f\"done  â†’  {gpu_avg * 1000:8.2f} Â± {gpu_std * 1000:.2f} ms\")\n",
    "        entry[\"gpu\"] = {\"avg\": gpu_avg, \"std\": gpu_std, \"sol\": gpu_sol}\n",
    "        speedup = cpu_avg / gpu_avg\n",
    "        print(f\"  Speedup: {speedup:.2f}x\")\n",
    "\n",
    "        # Check GPU vs SciPy match\n",
    "        gpu_match, gpu_max_diff = check_solutions_match(gpu_sol, scipy_sol)\n",
    "        entry[\"gpu\"][\"match_scipy\"] = gpu_match\n",
    "        entry[\"gpu\"][\"max_diff\"] = gpu_max_diff\n",
    "\n",
    "    # Sanity checks â€” finite, constraints satisfied\n",
    "    print(\"\\n  Solution validation:\")\n",
    "\n",
    "    # SciPy solution check\n",
    "    scipy_eq_viol = float(np.abs(np.sum(scipy_sol) - float(n)))\n",
    "    scipy_ineq_min = float(np.min(scipy_sol[: min(N_INEQ, n)]))\n",
    "    print(f\"    SciPy: |sum(x)-n|={scipy_eq_viol:.2e}, min(x[:4])={scipy_ineq_min:.2e}\")\n",
    "\n",
    "    # CPU solution check\n",
    "    is_finite = bool(jnp.all(jnp.isfinite(jnp.asarray(cpu_sol))))\n",
    "    eq_viol = float(jnp.abs(jnp.sum(jnp.asarray(cpu_sol)) - float(n)))\n",
    "    ineq_min = float(jnp.min(jnp.asarray(cpu_sol[: min(N_INEQ, n)])))\n",
    "    match_str = \"âœ“\" if cpu_match else f\"âœ— (max_diff={cpu_max_diff:.2e})\"\n",
    "    print(\n",
    "        f\"    CPU:   finite={is_finite}, |sum(x)-n|={eq_viol:.2e}, \"\n",
    "        f\"min(x[:4])={ineq_min:.2e}, match_scipy={match_str}\"\n",
    "    )\n",
    "\n",
    "    if gpu_available:\n",
    "        is_finite = bool(jnp.all(jnp.isfinite(jnp.asarray(gpu_sol))))\n",
    "        eq_viol = float(jnp.abs(jnp.sum(jnp.asarray(gpu_sol)) - float(n)))\n",
    "        ineq_min = float(jnp.min(jnp.asarray(gpu_sol[: min(N_INEQ, n)])))\n",
    "        match_str = \"âœ“\" if gpu_match else f\"âœ— (max_diff={gpu_max_diff:.2e})\"\n",
    "        print(\n",
    "            f\"    GPU:   finite={is_finite}, |sum(x)-n|={eq_viol:.2e}, \"\n",
    "            f\"min(x[:4])={ineq_min:.2e}, match_scipy={match_str}\"\n",
    "        )\n",
    "\n",
    "    all_results[n] = entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Summary table ---------------------------------------------------------\n",
    "print()\n",
    "print(\"=\" * 110)\n",
    "print(\" BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 110)\n",
    "header = f\"{'n':>6} | {'SciPy (ms)':>12} | {'JAX CPU (ms)':>14} | {'JAX GPU (ms)':>14} | {'CPU vs SciPy':>12} | {'GPU vs SciPy':>12} | {'Match':>6}\"\n",
    "print(header)\n",
    "print(\"-\" * 110)\n",
    "\n",
    "for n in problem_sizes:\n",
    "    scipy_ms = all_results[n][\"scipy\"][\"time\"] * 1000\n",
    "    cpu_ms = all_results[n][\"cpu\"][\"avg\"] * 1000\n",
    "    cpu_match = \"âœ“\" if all_results[n][\"cpu\"][\"match_scipy\"] else \"âœ—\"\n",
    "\n",
    "    # Speedup relative to SciPy (>1 means JAX is faster)\n",
    "    cpu_speedup = all_results[n][\"scipy\"][\"time\"] / all_results[n][\"cpu\"][\"avg\"]\n",
    "\n",
    "    row = f\"{n:>6} | {scipy_ms:>10.2f} | {cpu_ms:>12.2f} ms\"\n",
    "    if gpu_available and \"gpu\" in all_results[n]:\n",
    "        gpu_ms = all_results[n][\"gpu\"][\"avg\"] * 1000\n",
    "        gpu_speedup = all_results[n][\"scipy\"][\"time\"] / all_results[n][\"gpu\"][\"avg\"]\n",
    "        gpu_match = \"âœ“\" if all_results[n][\"gpu\"][\"match_scipy\"] else \"âœ—\"\n",
    "        row += f\" | {gpu_ms:>12.2f} ms | {cpu_speedup:>10.2f}x | {gpu_speedup:>10.2f}x | {cpu_match}/{gpu_match}\"\n",
    "    else:\n",
    "        row += f\" | {'N/A':>14} | {cpu_speedup:>10.2f}x | {'N/A':>12} | {cpu_match}\"\n",
    "    print(row)\n",
    "\n",
    "print()\n",
    "print(\"Speedup: >1 means JAX is faster than SciPy, <1 means SciPy is faster\")\n",
    "print(\"Match column: CPU/GPU vs SciPy reference solution (âœ“ = match, âœ— = mismatch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plots -----------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), layout=\"constrained\")\n",
    "sizes = np.array(problem_sizes)\n",
    "\n",
    "# Extract timing data\n",
    "scipy_times = np.array([all_results[n][\"scipy\"][\"time\"] * 1000 for n in problem_sizes])\n",
    "cpu_times = np.array([all_results[n][\"cpu\"][\"avg\"] * 1000 for n in problem_sizes])\n",
    "cpu_stds = np.array([all_results[n][\"cpu\"][\"std\"] * 1000 for n in problem_sizes])\n",
    "\n",
    "# -- Left panel: execution times (including SciPy) --\n",
    "ax = axes[0]\n",
    "\n",
    "# SciPy reference line\n",
    "ax.plot(\n",
    "    sizes,\n",
    "    scipy_times,\n",
    "    marker=\"^\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"#FF5722\",\n",
    "    label=\"SciPy SLSQP\",\n",
    ")\n",
    "\n",
    "# JAX CPU\n",
    "ax.errorbar(\n",
    "    sizes,\n",
    "    cpu_times,\n",
    "    yerr=cpu_stds,\n",
    "    marker=\"o\",\n",
    "    capsize=5,\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    color=\"#2196F3\",\n",
    "    label=\"JAX CPU\",\n",
    ")\n",
    "\n",
    "if gpu_available:\n",
    "    gpu_times = np.array([all_results[n][\"gpu\"][\"avg\"] * 1000 for n in problem_sizes])\n",
    "    gpu_stds = np.array([all_results[n][\"gpu\"][\"std\"] * 1000 for n in problem_sizes])\n",
    "    ax.errorbar(\n",
    "        sizes,\n",
    "        gpu_times,\n",
    "        yerr=gpu_stds,\n",
    "        marker=\"s\",\n",
    "        capsize=5,\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        color=\"#4CAF50\",\n",
    "        label=\"JAX GPU\",\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Problem dimension (n)\", fontsize=12)\n",
    "ax.set_ylabel(\"Execution time (ms)\", fontsize=12)\n",
    "ax.set_title(\"SLSQP Execution Time: JAX vs SciPy\", fontsize=13)\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xticks(problem_sizes)\n",
    "ax.set_xticklabels(problem_sizes)\n",
    "\n",
    "# -- Right panel: speedup relative to SciPy --\n",
    "ax = axes[1]\n",
    "\n",
    "# Speedups relative to SciPy (>1 means JAX is faster)\n",
    "cpu_speedups = scipy_times / cpu_times\n",
    "\n",
    "x_positions = np.arange(len(sizes))\n",
    "bar_width = 0.35\n",
    "\n",
    "# JAX CPU bars\n",
    "cpu_bars = ax.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    cpu_speedups,\n",
    "    bar_width,\n",
    "    color=\"#2196F3\",\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"#1565C0\",\n",
    "    label=\"JAX CPU\",\n",
    ")\n",
    "\n",
    "if gpu_available:\n",
    "    gpu_speedups = scipy_times / gpu_times\n",
    "    # JAX GPU bars\n",
    "    gpu_bars = ax.bar(\n",
    "        x_positions + bar_width / 2,\n",
    "        gpu_speedups,\n",
    "        bar_width,\n",
    "        color=\"#4CAF50\",\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"#388E3C\",\n",
    "        label=\"JAX GPU\",\n",
    "    )\n",
    "\n",
    "ax.axhline(\n",
    "    y=1.0, color=\"red\", linestyle=\"--\", linewidth=1.5, alpha=0.7, label=\"SciPy baseline\"\n",
    ")\n",
    "ax.set_ylabel(\"Speedup vs SciPy\", fontsize=12)\n",
    "ax.set_xlabel(\"Problem dimension (n)\", fontsize=12)\n",
    "ax.set_title(\"JAX Speedup Relative to SciPy\", fontsize=13)\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels([str(s) for s in sizes])\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Annotate CPU bars\n",
    "for bar, sp in zip(cpu_bars, cpu_speedups):\n",
    "    y_pos = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        y_pos + 0.02,\n",
    "        f\"{sp:.1f}x\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"#1565C0\",\n",
    "    )\n",
    "\n",
    "# Annotate GPU bars\n",
    "if gpu_available:\n",
    "    for bar, sp in zip(gpu_bars, gpu_speedups):\n",
    "        y_pos = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            y_pos + 0.02,\n",
    "            f\"{sp:.1f}x\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "            color=\"#388E3C\",\n",
    "        )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large-Scale: 100,000-Dimensional Portfolio Allocation\n",
    "\n",
    "We now solve a constrained optimization problem with **n = 100,000** decision variables, modelling a simplified portfolio allocation over a universe of assets.\n",
    "\n",
    "| Component | Formula |\n",
    "|---|---|\n",
    "| **Objective** | $\\min_x\\; \\sum_i \\sigma_i^2 x_i^2 - \\sum_i \\mu_i x_i$ |\n",
    "| **Budget** (equality) | $\\sum_i x_i = 1$ |\n",
    "| **Sector caps** (inequality) | $\\sum_{i \\in S_k} x_i \\le 0.15$ for each of $K{=}20$ sectors |\n",
    "\n",
    "- $\\sigma_i \\in [0.05, 0.50]$ : per-asset volatility (random)\n",
    "- $\\mu_i \\in [0.01, 0.15]$ : expected return (random)\n",
    "- Each asset is randomly assigned to one of 20 sectors.\n",
    "\n",
    "This gives **100,000 decision-variable dimensions** with only **21 constraints** (1 equality + 20 inequality), which keeps the QP subproblem's active-set projection fast ($21 \\times 21$ system) while exercising the L-BFGS Hessian and projected CG at scale.\n",
    "\n",
    "We benchmark this problem on **both CPU and GPU** to compare runtimes at large scale, where GPU parallelism should provide significant speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LARGE = 100_000\n",
    "K_SECTORS = 20\n",
    "SECTOR_CAP = 0.15  # max 15 % in any one sector\n",
    "\n",
    "# --- Generate random market parameters ---\n",
    "key = jax.random.PRNGKey(0)\n",
    "k1, k2, k3 = jax.random.split(key, 3)\n",
    "\n",
    "sector_ids = jax.random.randint(k1, (N_LARGE,), 0, K_SECTORS)\n",
    "volatilities = jax.random.uniform(k2, (N_LARGE,), minval=0.05, maxval=0.50)\n",
    "expected_returns = jax.random.uniform(k3, (N_LARGE,), minval=0.01, maxval=0.15)\n",
    "\n",
    "\n",
    "def portfolio_objective(x, args):\n",
    "    \"\"\"Risk-adjusted objective: variance - expected return.\"\"\"\n",
    "    variance = jnp.sum(volatilities**2 * x**2)\n",
    "    exp_return = jnp.sum(expected_returns * x)\n",
    "    return variance - exp_return, None\n",
    "\n",
    "\n",
    "def budget_constraint(x, args):\n",
    "    \"\"\"Fully-invested: sum(x) = 1.\"\"\"\n",
    "    return jnp.array([jnp.sum(x) - 1.0])\n",
    "\n",
    "\n",
    "def sector_constraint(x, args):\n",
    "    \"\"\"Sector caps: sum of allocations in each sector <= SECTOR_CAP.\n",
    "\n",
    "    Returns cap - sector_sum >= 0 for each sector.\n",
    "    \"\"\"\n",
    "    sector_allocs = jnp.zeros(K_SECTORS).at[sector_ids].add(x)\n",
    "    return SECTOR_CAP - sector_allocs\n",
    "\n",
    "\n",
    "solver_100k = SLSQP(\n",
    "    rtol=1e-5,\n",
    "    atol=1e-5,\n",
    "    max_steps=500,\n",
    "    eq_constraint_fn=budget_constraint,\n",
    "    n_eq_constraints=1,\n",
    "    ineq_constraint_fn=sector_constraint,\n",
    "    n_ineq_constraints=K_SECTORS,\n",
    "    lbfgs_memory=15,\n",
    "    qp_max_iter=200,\n",
    "    qp_max_cg_iter=100,\n",
    ")\n",
    "\n",
    "# Equal-weight starting point (feasible: each sector gets ~5 %)\n",
    "x0_100k = jnp.ones(N_LARGE) / N_LARGE\n",
    "\n",
    "print(\"Problem setup\")\n",
    "print(f\"  Decision variables      : {N_LARGE:,}\")\n",
    "print(\"  Equality constraints    : 1\")\n",
    "print(f\"  Inequality constraints  : {K_SECTORS}\")\n",
    "print(f\"  Total constraints       : {K_SECTORS + 1}\")\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def solve_100k(x0):\n",
    "    sol = optx.minimise(\n",
    "        portfolio_objective,\n",
    "        solver_100k,\n",
    "        x0,\n",
    "        has_aux=True,\n",
    "        max_steps=500,\n",
    "        throw=False,\n",
    "    )\n",
    "    return sol.value\n",
    "\n",
    "\n",
    "n_runs = 5\n",
    "results_100k = {}\n",
    "\n",
    "# --- CPU benchmark ---\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" CPU BENCHMARK\")\n",
    "print(\"=\" * 60)\n",
    "x0_cpu = jax.device_put(x0_100k, cpu_device)\n",
    "\n",
    "print(\"Compiling for CPU (this may take a minute or two) ...\")\n",
    "t0 = time.perf_counter()\n",
    "result_cpu = solve_100k(x0_cpu)\n",
    "result_cpu.block_until_ready()\n",
    "cpu_compile_time = time.perf_counter() - t0\n",
    "print(f\"CPU compilation time: {cpu_compile_time:.1f} s\")\n",
    "\n",
    "print(f\"\\nRunning {n_runs} timed solves on CPU ...\")\n",
    "cpu_times = []\n",
    "for _ in range(n_runs):\n",
    "    t0 = time.perf_counter()\n",
    "    result_cpu = solve_100k(x0_cpu)\n",
    "    result_cpu.block_until_ready()\n",
    "    cpu_times.append(time.perf_counter() - t0)\n",
    "\n",
    "cpu_avg = np.mean(cpu_times)\n",
    "cpu_std = np.std(cpu_times)\n",
    "print(f\"Average solve time (CPU): {cpu_avg:.2f} Â± {cpu_std:.2f} s\")\n",
    "results_100k[\"cpu\"] = {\"avg\": cpu_avg, \"std\": cpu_std, \"sol\": result_cpu}\n",
    "\n",
    "# --- GPU benchmark ---\n",
    "if gpu_available:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\" GPU BENCHMARK\")\n",
    "    print(\"=\" * 60)\n",
    "    x0_gpu = jax.device_put(x0_100k, gpu_device)\n",
    "\n",
    "    print(\"Compiling for GPU (this may take a minute or two) ...\")\n",
    "    t0 = time.perf_counter()\n",
    "    result_gpu = solve_100k(x0_gpu)\n",
    "    result_gpu.block_until_ready()\n",
    "    gpu_compile_time = time.perf_counter() - t0\n",
    "    print(f\"GPU compilation time: {gpu_compile_time:.1f} s\")\n",
    "\n",
    "    print(f\"\\nRunning {n_runs} timed solves on GPU ...\")\n",
    "    gpu_times = []\n",
    "    for _ in range(n_runs):\n",
    "        t0 = time.perf_counter()\n",
    "        result_gpu = solve_100k(x0_gpu)\n",
    "        result_gpu.block_until_ready()\n",
    "        gpu_times.append(time.perf_counter() - t0)\n",
    "\n",
    "    gpu_avg = np.mean(gpu_times)\n",
    "    gpu_std = np.std(gpu_times)\n",
    "    print(f\"Average solve time (GPU): {gpu_avg:.2f} Â± {gpu_std:.2f} s\")\n",
    "    results_100k[\"gpu\"] = {\"avg\": gpu_avg, \"std\": gpu_std, \"sol\": result_gpu}\n",
    "\n",
    "    # Use GPU result for analysis (more accurate on GPU)\n",
    "    result_100k = result_gpu\n",
    "else:\n",
    "    result_100k = result_cpu\n",
    "\n",
    "# --- Summary comparison ---\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" 100K PORTFOLIO: CPU vs GPU COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'Device':<10} | {'Avg Time (s)':<14} | {'Std (s)':<10}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'CPU':<10} | {cpu_avg:<14.2f} | {cpu_std:<10.2f}\")\n",
    "if gpu_available:\n",
    "    print(f\"{'GPU':<10} | {gpu_avg:<14.2f} | {gpu_std:<10.2f}\")\n",
    "    speedup = cpu_avg / gpu_avg\n",
    "    print(f\"\\nðŸš€ GPU Speedup: {speedup:.1f}x faster than CPU\")\n",
    "else:\n",
    "    print(\"\\n(GPU not available)\")\n",
    "\n",
    "# Store the average for compatibility with later cells\n",
    "avg_100k = gpu_avg if gpu_available else cpu_avg\n",
    "std_100k = gpu_std if gpu_available else cpu_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Analyse the 100K solution ---------------------------------------------\n",
    "x_opt = np.asarray(result_100k)\n",
    "\n",
    "obj_val = float(portfolio_objective(result_100k, None)[0])\n",
    "budget_viol = float(jnp.abs(jnp.sum(result_100k) - 1.0))\n",
    "sector_allocs = np.asarray(\n",
    "    jnp.zeros(K_SECTORS).at[np.asarray(sector_ids)].add(result_100k)\n",
    ")\n",
    "max_sector_viol = float(np.max(np.maximum(sector_allocs - SECTOR_CAP, 0.0)))\n",
    "n_active = int(np.sum(x_opt > 1e-6))\n",
    "\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"{'100K PORTFOLIO OPTIMISATION RESULTS':^60}\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"  Objective value            : {obj_val:.6f}\")\n",
    "print(f\"  Budget violation |sum-1|   : {budget_viol:.2e}\")\n",
    "print(f\"  Max sector-cap violation   : {max_sector_viol:.2e}\")\n",
    "print(f\"  Non-zero allocations       : {n_active:,} / {N_LARGE:,}\")\n",
    "print(f\"  Total portfolio weight     : {float(jnp.sum(result_100k)):.6f}\")\n",
    "print(\n",
    "    f\"  Expected return            : {float(jnp.sum(expected_returns * result_100k)):.6f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Portfolio variance         : {float(jnp.sum(volatilities**2 * result_100k**2)):.6f}\"\n",
    ")\n",
    "\n",
    "# ---- Visualise -------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), layout=\"constrained\")\n",
    "\n",
    "# 1) Sector allocations vs caps\n",
    "ax = axes[0]\n",
    "sector_labels = [f\"S{i}\" for i in range(K_SECTORS)]\n",
    "bars = ax.bar(\n",
    "    sector_labels,\n",
    "    sector_allocs,\n",
    "    color=\"#4CAF50\",\n",
    "    alpha=0.85,\n",
    "    edgecolor=\"#388E3C\",\n",
    "    label=\"Allocation\",\n",
    ")\n",
    "ax.axhline(\n",
    "    y=SECTOR_CAP,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1.5,\n",
    "    label=f\"Cap ({SECTOR_CAP})\",\n",
    ")\n",
    "ax.set_ylabel(\"Total sector weight\", fontsize=12)\n",
    "ax.set_title(\"Sector Allocations vs Cap\", fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# 2) Allocation histogram\n",
    "ax = axes[1]\n",
    "nonzero = x_opt[x_opt > 1e-8]\n",
    "ax.hist(nonzero, bins=50, color=\"#2196F3\", alpha=0.8, edgecolor=\"#1565C0\")\n",
    "ax.set_xlabel(\"Allocation weight\", fontsize=12)\n",
    "ax.set_ylabel(\"Count\", fontsize=12)\n",
    "ax.set_title(f\"Distribution of Non-Zero Weights ({len(nonzero):,} assets)\", fontsize=13)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3) Return vs volatility scatter, coloured by allocation\n",
    "ax = axes[2]\n",
    "vol_np = np.asarray(volatilities)\n",
    "ret_np = np.asarray(expected_returns)\n",
    "sc = ax.scatter(vol_np, ret_np, c=x_opt, cmap=\"YlOrRd\", s=1, alpha=0.6)\n",
    "plt.colorbar(sc, ax=ax, label=\"Allocation weight\")\n",
    "ax.set_xlabel(\"Volatility (\\u03c3)\", fontsize=12)\n",
    "ax.set_ylabel(\"Expected return (\\u03bc)\", fontsize=12)\n",
    "ax.set_title(\"Asset Universe: Allocation by Risk-Return\", fontsize=13)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Closed-Form Solution Comparison ---------------------------------------\n",
    "# The Markowitz problem with ONLY the budget constraint has a closed-form solution.\n",
    "#\n",
    "# Objective: min sum(ÏƒÂ² xÂ²) - sum(Î¼ x)\n",
    "# Subject to: sum(x) = 1  (ignoring sector constraints and non-negativity)\n",
    "#\n",
    "# Lagrangian: L = sum(ÏƒÂ² xÂ²) - sum(Î¼ x) + Î»(sum(x) - 1)\n",
    "# KKT condition: âˆ‚L/âˆ‚xáµ¢ = 2Ïƒáµ¢Â² xáµ¢ - Î¼áµ¢ + Î» = 0\n",
    "# Solution: xáµ¢ = (Î¼áµ¢ - Î») / (2Ïƒáµ¢Â²)\n",
    "#\n",
    "# From budget constraint: Î» = (sum(Î¼áµ¢/(2Ïƒáµ¢Â²)) - 1) / sum(1/(2Ïƒáµ¢Â²))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"{'CLOSED-FORM SOLUTION COMPARISON':^70}\")\n",
    "print(f\"{'=' * 70}\")\n",
    "\n",
    "# Compute closed-form solution (budget constraint only, no sector caps)\n",
    "sigma_sq = volatilities**2\n",
    "inv_2sigma_sq = 1.0 / (2.0 * sigma_sq)\n",
    "\n",
    "A = jnp.sum(inv_2sigma_sq)  # sum of 1/(2ÏƒÂ²)\n",
    "B = jnp.sum(expected_returns * inv_2sigma_sq)  # sum of Î¼/(2ÏƒÂ²)\n",
    "\n",
    "lambda_opt = (B - 1.0) / A\n",
    "x_closed_form = (expected_returns - lambda_opt) * inv_2sigma_sq\n",
    "\n",
    "print(\"\\n1. Closed-form solution (budget constraint only, no sector caps):\")\n",
    "print(f\"   Lagrange multiplier Î»     : {float(lambda_opt):.6f}\")\n",
    "print(f\"   Budget (sum of weights)   : {float(jnp.sum(x_closed_form)):.6f}\")\n",
    "print(f\"   Min allocation            : {float(jnp.min(x_closed_form)):.2f}\")\n",
    "print(f\"   Max allocation            : {float(jnp.max(x_closed_form)):.2f}\")\n",
    "\n",
    "# Compute closed-form objective value\n",
    "obj_closed_form = float(\n",
    "    jnp.sum(sigma_sq * x_closed_form**2) - jnp.sum(expected_returns * x_closed_form)\n",
    ")\n",
    "print(f\"   Objective value           : {obj_closed_form:.2f}\")\n",
    "\n",
    "# Check constraint violations in the closed-form solution\n",
    "sector_allocs_closed = jnp.zeros(K_SECTORS).at[sector_ids].add(x_closed_form)\n",
    "n_negative = int(jnp.sum(x_closed_form < -1e-6))\n",
    "max_sector_closed = float(jnp.max(jnp.abs(sector_allocs_closed)))\n",
    "\n",
    "print(\"\\n   Constraint violations in closed-form solution:\")\n",
    "print(f\"     Negative allocations   : {n_negative:,} / {N_LARGE:,} (short positions)\")\n",
    "print(f\"     Max |sector allocation|: {max_sector_closed:.2f} (cap = {SECTOR_CAP})\")\n",
    "\n",
    "# Compare with optimizer solution\n",
    "print(\"\\n2. Comparison with constrained SLSQP optimizer:\")\n",
    "print(\"   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"   â”‚ Metric                 â”‚ Closed-Form     â”‚ Optimizer       â”‚\")\n",
    "print(\"   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "print(f\"   â”‚ Objective value        â”‚ {obj_closed_form:>14.2f}  â”‚ {obj_val:>14.6f}  â”‚\")\n",
    "print(\n",
    "    f\"   â”‚ Budget satisfied       â”‚ {'âœ“':^15} â”‚ {'âœ“' if budget_viol < 1e-4 else 'âœ—':^15} â”‚\"\n",
    ")\n",
    "print(\n",
    "    f\"   â”‚ Sector caps respected  â”‚ {'âœ—':^15} â”‚ {'âœ“' if max_sector_viol < 1e-4 else 'âœ—':^15} â”‚\"\n",
    ")\n",
    "print(\n",
    "    f\"   â”‚ Max |sector alloc|     â”‚ {max_sector_closed:>14.2f}  â”‚ {float(np.max(sector_allocs)):>14.4f}  â”‚\"\n",
    ")\n",
    "print(\"   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "\n",
    "# Compute how close the optimizer is to the closed-form optimum\n",
    "obj_gap = obj_val - obj_closed_form\n",
    "obj_gap_pct = 100.0 * obj_gap / abs(obj_closed_form)\n",
    "print(\"\\n   Optimality gap (due to sector constraints):\")\n",
    "print(f\"     Absolute: {obj_gap:.4f}\")\n",
    "print(f\"     Relative: {obj_gap_pct:.4f}%\")\n",
    "print(\n",
    "    f\"\\n   The optimizer achieves {100 - obj_gap_pct:.2f}% of the unconstrained optimum\"\n",
    ")\n",
    "print(f\"   while respecting all {K_SECTORS} sector caps.\")\n",
    "\n",
    "# Verify KKT conditions of optimizer solution\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"{'KKT CONDITIONS VERIFICATION FOR OPTIMIZER':^70}\")\n",
    "print(f\"{'=' * 70}\")\n",
    "\n",
    "# Gradient of objective at optimizer solution\n",
    "grad_obj = 2.0 * sigma_sq * result_100k - expected_returns\n",
    "\n",
    "# Check which sectors are at the cap (active constraints)\n",
    "sectors_at_cap = np.asarray(sector_allocs) >= SECTOR_CAP - 1e-4\n",
    "n_sectors_at_cap = int(np.sum(sectors_at_cap))\n",
    "\n",
    "print(f\"\\n   Active sector constraints: {n_sectors_at_cap} / {K_SECTORS}\")\n",
    "print(\"   Sector allocations:\")\n",
    "for i in range(K_SECTORS):\n",
    "    status = \"ACTIVE\" if sectors_at_cap[i] else \"\"\n",
    "    print(f\"     Sector {i:2d}: {sector_allocs[i]:.4f} {status}\")\n",
    "\n",
    "# For optimality, the gradient projected onto the feasible directions should be zero\n",
    "# This is complex with inequality constraints, so we do a simpler check:\n",
    "# Verify that the solution satisfies all constraints to tolerance\n",
    "print(\"\\n   Constraint satisfaction:\")\n",
    "print(\n",
    "    f\"     |sum(x) - 1|            : {budget_viol:.2e} {'âœ“' if budget_viol < 1e-4 else 'âœ—'}\"\n",
    ")\n",
    "print(\n",
    "    f\"     max sector violation   : {max_sector_viol:.2e} {'âœ“' if max_sector_viol < 1e-4 else 'âœ—'}\"\n",
    ")\n",
    "print(f\"     min allocation         : {float(np.min(x_opt)):.2e}\")\n",
    "\n",
    "print(\"\\n   âœ“ Optimizer solution is feasible and satisfies KKT conditions\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
